{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pollyjuice74/REU-LDPC-Project/blob/main/LinearTranDiff_on_5G.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXwLdxMGTjF8"
      },
      "outputs": [],
      "source": [
        "# Source code\n",
        "!git clone https://github.com/pollyjuice74/REU-LDPC-Project\n",
        "!git clone https://github.com/pollyjuice74/DDECC\n",
        "# Sionna stuff\n",
        "!git clone https://github.com/NVlabs/sionna.git\n",
        "!pip install mitsuba\n",
        "!pip install pythreejs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e-lnoCOdT9LS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import time\n",
        "import os\n",
        "from scipy.sparse import issparse, csr_matrix, coo_matrix\n",
        "\n",
        "\n",
        "# os.chdir('../..')\n",
        "os.chdir('sionna')\n",
        "from sionna.fec.ldpc.encoding import * # 5g encoder\n",
        "\n",
        "from sionna.utils.metrics import compute_ber, compute_bler\n",
        "from sionna.utils import BitErrorRate, BinarySource, ebnodb2no\n",
        "\n",
        "from sionna.mapping import Constellation, Mapper, Demapper\n",
        "from sionna.channel import AWGN\n",
        "os.chdir('..')\n",
        "\n",
        "if os.path.exists('REU-LDPC-Project'):\n",
        "  os.rename('REU-LDPC-Project', 'REU_LDPC_Project')\n",
        "\n",
        "os.chdir('REU_LDPC_Project/adv_nn')\n",
        "from attention import *\n",
        "from channel import *\n",
        "from transformer import *\n",
        "from dataset import *\n",
        "from args import *\n",
        "from model_functs import *\n",
        "from models import *\n",
        "from decoder5G import * # 5g decoder\n",
        "\n",
        "os.chdir('../..')\n",
        "from DDECC.src.codes import EbN0_to_std\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class TransformerDiffusion( Layer ):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.model_type = args.model_type\n",
        "        self.n_steps = args.n_steps\n",
        "\n",
        "        code = args.code\n",
        "        assert issparse(code.H), \"Code's pcm must be sparse.\"\n",
        "        self.pcm = code.H\n",
        "\n",
        "        self.m, self.n = self.pcm.shape\n",
        "        self.k = self.n - self.m\n",
        "\n",
        "        self.mask = self.create_mask(self.pcm)\n",
        "        self.src_embed = tf.Variable( tf.random.uniform([1, self.n + self.m, args.d_model]), trainable=True )\n",
        "        self.decoder = Transformer(args.d_model, args.heads, self.mask, args.t_layers)\n",
        "        self.fc = Dense(1)\n",
        "        self.to_n = Dense(1)\n",
        "        self.time_embed = Embedding(args.n_steps, args.d_model)\n",
        "\n",
        "        self.betas = tf.constant( tf.linspace(1e-3, 1e-2, args.n_steps)*0 + args.sigma )\n",
        "        self.betas_bar = tf.constant( tf.math.cumsum(self.betas, 0) )\n",
        "        self.ls_active = args.ls_active\n",
        "\n",
        "    # Extracts noise estimate z_hat from r\n",
        "    def tran_call(self, r_t, t):\n",
        "        # Make sure r_t and t are compatible\n",
        "        r_t = tf.reshape(r_t, (self.n, -1)) # (n,b)\n",
        "        t = tf.cast(t, dtype=tf.int32)\n",
        "\n",
        "        # Compute synd and magn\n",
        "        syndrome = tf.reshape( self.get_syndrome(llr_to_bin(r_t)), (self.pcm.shape[0], -1) ) # (m,n)@(n,b)->(m,b) check nodes\n",
        "        magnitude = tf.reshape( tf.abs(r_t), (self.n, -1) ) #(n,b) variable nodes\n",
        "        # make sure their the same dtype\n",
        "        magnitude, syndrome = [ tf.cast(tensor, dtype=tf.float32) for tensor in [magnitude, syndrome] ]\n",
        "\n",
        "        # Concatenate synd and magn\n",
        "        nodes = tf.concat([magnitude, syndrome], axis=0) # data for vertices\n",
        "        nodes = tf.reshape(nodes, (1, self.pcm.shape[0]+self.n, -1)) # (1, n+m, b)\n",
        "        print(nodes.shape)\n",
        "\n",
        "        # Embedding nodes w/ attn and 'time' (sum syn errs) dims\n",
        "        nodes_emb = tf.reshape( self.src_embed * nodes, (self.src_embed.shape[-1], self.pcm.shape[0]+self.n, -1) ) # (d,n+m,b)\n",
        "        time_emb = tf.reshape( self.time_embed(t), (self.src_embed.shape[-1], 1, -1) ) # (d,1,b)\n",
        "\n",
        "        # Applying embeds\n",
        "        emb_t = time_emb * nodes_emb # (d, n+m, b)\n",
        "        logits = self.decoder(emb_t) # (d, n+m, d) # TODO: missing batch dims b\n",
        "        print(emb_t.shape, logits.shape)\n",
        "\n",
        "        # Reduce (d,n+m,d)->(d,n+m)\n",
        "        logits = tf.squeeze( self.fc(logits), axis=-1 )\n",
        "        node_logits = tf.reshape( logits[:, :self.n], (self.n, -1) ) # (n,d) take the first n logits from the concatenation\n",
        "        # (n,d)->(n,)\n",
        "        z_hat = self.to_n(node_logits)\n",
        "        print(logits.shape, z_hat.shape)\n",
        "        return z_hat\n",
        "\n",
        "    # optimal lambda l for theoretical and for error prediction\n",
        "    def line_search(self, r_t, sigma, err_hat, lin_splits=20):\n",
        "        l_values =  tf.reshape( tf.linspace(1., 20., lin_splits), (1, 1, lin_splits) )\n",
        "        r_t, sigma, err_hat = [ tf.expand_dims(tensor, axis=-1) for tensor in [r_t, sigma, err_hat] ]# (n,b, 1)\n",
        "\n",
        "        # Compute theoretical step size w/ ls splits\n",
        "        z_hat_values = l_values*(sigma*err_hat) # (n,b, l), l is lin_splits\n",
        "        r_values = llr_to_bin(r_t - z_hat_values) # (n,b, l)\n",
        "        # sum of synds (m,n)@(n,b*l)->(m,b*l)->(b*l, 1)\n",
        "        sum_synds = tf.reduce_sum( self.pcm.dot( tf.squeeze(r_values, axis=1) ) % 2, axis=0 )[:, tf.newaxis]\n",
        "        print(sum_synds.shape)\n",
        "\n",
        "        # Pick optimal ls value\n",
        "        if self.model_type=='dis':\n",
        "             ixs = tf.math.argmin(sum_synds, axis=-1, output_type=tf.int32) # (b,1) w/ ixs of optimal line search for batch b\n",
        "        elif self.model_type=='gen':\n",
        "             ixs = tf.math.argmax(sum_synds, axis=-1, output_type=tf.int32) # (b,1)\n",
        "\n",
        "        print(r_values.shape, z_hat_values.shape)\n",
        "        # (b, l, n) for indexing on l\n",
        "        r_values, z_hat_values = [ tf.transpose(tensor, perm=[1,2,0])\n",
        "                                            for tensor in [r_values, z_hat_values] ]\n",
        "\n",
        "        # concat range of batch ixs [0,...,n-1] and optimal line search ixs in gather_nd\n",
        "        indices = tf.concat([ tf.range(ixs.shape[0])[:, tf.newaxis], ixs], axis=-1) # (b,2)\n",
        "\n",
        "        # print(r_values, z_hat_values, indices)\n",
        "        # ix on lin_splits w/ gather_nd st. ix,(b, l, n)->(n,b)\n",
        "        r_t1, z_hat = [ tf.reshape( tf.gather_nd(tensor, indices), (self.n, -1) )\n",
        "                                             for tensor in [r_values, z_hat_values] ]\n",
        "        return r_t1, z_hat # r at t-1\n",
        "\n",
        "    def train(self, c_0, struct_noise=0, sim_ampl=True):\n",
        "        t = tf.random.uniform( (c_0.shape[0] // 2 + 1,), minval=0,maxval=self.n_steps, dtype=tf.int32 )\n",
        "        t = tf.concat([t, self.n_steps - t - 1], axis=0)[:c_0.shape[0]] # reshapes t to size x_0\n",
        "        t = tf.cast(t, dtype=tf.int32)\n",
        "\n",
        "        noise_factor = tf.math.sqrt( tf.gather(self.betas_bar, t) )\n",
        "        noise_factor = tf.reshape(noise_factor, (-1, 1))\n",
        "        z = tf.random.normal(c_0.shape)\n",
        "        h = np.random.rayleigh(size=c_0.shape)if sim_ampl else 1.\n",
        "\n",
        "        # added noise to codeword\n",
        "        c_t = tf.transpose(h * c_0 + struct_noise + (z*noise_factor))\n",
        "        # calculate sum of syndrome\n",
        "        t = tf.math.reduce_sum( self.get_syndrome( llr_to_bin(tf.sign(c_t)) ), axis=0 ) # (batch_size, 1)\n",
        "\n",
        "        z_hat = self.tran_call(c_t, t) # model prediction\n",
        "\n",
        "        if self.model_type=='dis':\n",
        "            z_mul = c_t * tf.transpose(c_0) # actual noise added through the channel\n",
        "\n",
        "        elif self.model_type=='gen':\n",
        "            c_t += z_hat # could contain positive or negative values\n",
        "            z_mul = c_t * tf.transpose(c_0) # moidfied channel noise st. it will fool the discriminator\n",
        "\n",
        "        z_mul = tf.reshape(z_mul, (z_hat.shape[0], -1))\n",
        "        return z_hat, llr_to_bin(z_mul), c_t\n",
        "\n",
        "    def create_mask(self, H):\n",
        "        m,n = H.shape\n",
        "        mask = tf.eye(n+m, dtype=tf.float32) # (n+m, n+m)\n",
        "        cn_con, vn_con, _ = sp.sparse.find(H)\n",
        "\n",
        "        for cn, vn_i in zip(cn_con, vn_con):\n",
        "            # cn to vn connections in the mask\n",
        "            mask = tf.tensor_scatter_nd_update(mask, [[n+cn, vn_i],[vn_i, n+cn]], [1.0,1.0])\n",
        "\n",
        "            # distance 2 vn neighbors of vn_i\n",
        "            related_vns = vn_con[cn_con==cn]\n",
        "            for vn_j in related_vns:\n",
        "                mask = tf.tensor_scatter_nd_update(mask, [[vn_i, vn_j],[vn_j, vn_i]], [1.0,1.0])\n",
        "\n",
        "        # -infinity where mask is not set\n",
        "        mask = tf.where(mask == 1.0,\n",
        "                        mask, -tf.constant(float('inf'), dtype=tf.float32))\n",
        "        return mask\n",
        "\n",
        "    def get_sigma(self, t):\n",
        "        # make sure t is a positive int\n",
        "        t = tf.cast( tf.abs(t), tf.int32 )\n",
        "        # gather betas\n",
        "        betas_t = tf.gather(self.betas, t)\n",
        "        betas_bar_t = tf.gather(self.betas_bar, t)\n",
        "\n",
        "        return betas_bar_t * betas_t / (betas_bar_t + betas_t)\n",
        "\n",
        "    def get_syndrome(self, r_t):\n",
        "        # Calculate syndrome (pcm @ r = 0) if r is correct in binary\n",
        "        r_t = tf.reshape(r_t, (self.n, -1)) # (n,b)\n",
        "        return self.pcm.dot( llr_to_bin( r_t ).numpy() ) % 2 # (m,n)@(n,b)->(m,b)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Decoder( TransformerDiffusion ):\n",
        "    def __init__(self, args):\n",
        "        super().__init__(args)\n",
        "\n",
        "    # 'test' function\n",
        "    def call(self, r_t):\n",
        "       for i in range(self.m):\n",
        "           print(r_t.shape)\n",
        "           r_t, z_hat = self.rev_diff_call(r_t) # both (n,)\n",
        "\n",
        "           # Check if synd is 0 return r_t\n",
        "           if tf.reduce_sum( self.get_syndrome(r_t) ) == 0:\n",
        "               return r_t, z_hat, i\n",
        "\n",
        "       return r_t, z_hat, i\n",
        "\n",
        "    # Refines recieved codeword r at time t\n",
        "    def rev_diff_call(self, r_t):\n",
        "        print(\"Rev def call...\")\n",
        "        # Make sure r_t and t are compatible\n",
        "        r_t = tf.reshape(r_t, (self.n, -1)) # (n,b)\n",
        "        # 'time step' of diffusion is really ix of abs(sum synd errors)\n",
        "        t = tf.reduce_sum( self.get_syndrome(llr_to_bin(r_t)), axis=0 ) # (m,n)@(n,b)->(m,b)->(1,b)\n",
        "        t = tf.cast(tf.abs(t), dtype=tf.int32)\n",
        "\n",
        "        # Transformer error prediction\n",
        "        z_hat_crude = self.tran_call(r_t, t) # (n,1)\n",
        "\n",
        "        # Compute diffusion vars\n",
        "        sigma = self.get_sigma(t) # theoretical step size\n",
        "        print(r_t.shape, z_hat_crude.shape, r_t.shape)\n",
        "        err_hat = r_t - tf.sign(z_hat_crude * r_t) # (n,1)\n",
        "\n",
        "        # Refined estimate of the codeword for the ls diffusion step\n",
        "        r_t1, z_hat = self.line_search(r_t, sigma, err_hat) if self.ls_active else 1.\n",
        "        # r_t1[t==0] = r_t[t==0] # if cw has 0 synd. keep as is\n",
        "\n",
        "        return r_t1, z_hat # r at t-1, both (n,1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "args = Args(model_type='dis', code_type='LDPC5G') # args for decoder/discriminator\n",
        "\n",
        "# Define enc/dec layers #\n",
        "enc5G = LDPC5GEncoder(args.k, args.n)\n",
        "dec5G = LDPC5GDecoder(enc5G, args)\n",
        "\n",
        "binary_source = BinarySource()\n",
        "\n",
        "# initialize mapper and demapper for constellation object\n",
        "constellation = Constellation(\"qam\", num_bits_per_symbol=4)\n",
        "mapper = Mapper(constellation=constellation)\n",
        "demapper = Demapper(\"app\", constellation=constellation)\n",
        "\n",
        "channel = AWGN() # replace w/ Generator(args)\n",
        "\n",
        "no = ebnodb2no(1, 11, args.k/args.n) # eb_no=1, bps=4\n",
        "no = tf.expand_dims(tf.cast(no, tf.float32), axis=-1)\n",
        "\n",
        "\n",
        "# Simulate #\n",
        "u = binary_source([1, args.k])\n",
        "c = enc5G(u) # (1,n)\n",
        "\n",
        "x = mapper(c) # map c to symbols x\n",
        "y = channel([x, no]) # transmit over AWGN channel\n",
        "llr_ch = demapper([y, no]) # demap y to LLRs (1,n)\n",
        "\n",
        "llr_5g = dec5G(llr_ch) # u_hat = dec5G(llr_ch) # run FEC decoder (incl. rate-recovery)\n",
        "\n",
        "args.code.H = dec5G.pcm\n",
        "dec = Decoder(args)\n",
        "\n",
        "dec(llr_5g)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946
        },
        "id": "eYSwka9S8OJa",
        "outputId": "730c7e98-5475-4420-f621-fcc59add5fbb"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 512)\n",
            "Rev def call...\n",
            "(1, 764, 1)\n",
            "(128, 764, 1) (128, 764, 128)\n",
            "(128, 764) (512, 1)\n",
            "(512, 1) (512, 1) (512, 1)\n",
            "(20, 1)\n",
            "(512, 1, 20) (512, 1, 20)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Exception encountered when calling layer 'decoder_32' (type Decoder).\n\n{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Ranks of all input tensors should match: shape[0] = [20,1] vs. shape[1] = [20] [Op:ConcatV2] name: concat\n\nCall arguments received by layer 'decoder_32' (type Decoder):\n  • r_t=tf.Tensor(shape=(1, 512), dtype=float32)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-159630c84aa1>\u001b[0m in \u001b[0;36m<cell line: 230>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0mdec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m \u001b[0mdec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllr_5g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-75-159630c84aa1>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, r_t)\u001b[0m\n\u001b[1;32m    161\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m            \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m            \u001b[0mr_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrev_diff_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# both (n,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m            \u001b[0;31m# Check if synd is 0 return r_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-75-159630c84aa1>\u001b[0m in \u001b[0;36mrev_diff_call\u001b[0;34m(self, r_t)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;31m# Refined estimate of the codeword for the ls diffusion step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mr_t1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_hat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mls_active\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;31m# r_t1[t==0] = r_t[t==0] # if cw has 0 synd. keep as is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-75-159630c84aa1>\u001b[0m in \u001b[0;36mline_search\u001b[0;34m(self, r_t, sigma, err_hat, lin_splits)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# concat range of batch ixs [0,...,n-1] and optimal line search ixs in gather_nd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mixs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mixs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (b,2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# print(r_values, z_hat_values, indices)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'decoder_32' (type Decoder).\n\n{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Ranks of all input tensors should match: shape[0] = [20,1] vs. shape[1] = [20] [Op:ConcatV2] name: concat\n\nCall arguments received by layer 'decoder_32' (type Decoder):\n  • r_t=tf.Tensor(shape=(1, 512), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cn_con, vn_con, vals = sp.sparse.find(dec5G.pcm)\n",
        "cn_con, vn_con\n",
        "\n",
        "H = [[1,0,1,1,1,0,0],\n",
        "     [0,1,0,1,1,1,0],\n",
        "     [0,0,1,0,1,1,1]]\n",
        "H = csr_matrix(H)\n",
        "\n",
        "def get_syndrome(pcm, r_t):\n",
        "        # Calculate syndrome (pcm @ r = 0) if r is correct in binary\n",
        "        r_t = tf.reshape(r_t, (pcm.shape[1], -1)) # (n,b)\n",
        "        return pcm.dot(llr_to_bin(r_t).numpy()) % 2\n",
        "\n",
        "get_syndrome(dec5G.pcm, llr_5g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPTCo3dbFsJy",
        "outputId": "0f6bd466-2809-4fe0-efa1-2afaa1296187"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(252, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LDPC5GDecoder(LDPCBPDecoder):\n",
        "    def __init__(self,\n",
        "                 encoder,\n",
        "                 args,\n",
        "                 trainable=False,\n",
        "                 cn_type='boxplus-phi',\n",
        "                 hard_out=True,\n",
        "                 track_exit=False,\n",
        "                 return_infobits=True,\n",
        "                 prune_pcm=True,\n",
        "                 num_iter=20,\n",
        "                 stateful=False,\n",
        "                 output_dtype=tf.float32,\n",
        "                 **kwargs):\n",
        "\n",
        "        # needs the 5G Encoder to access all 5G parameters\n",
        "        assert isinstance(encoder, LDPC5GEncoder), 'encoder must \\\n",
        "                          be of class LDPC5GEncoder.'\n",
        "        self._encoder = encoder\n",
        "        pcm = encoder.pcm\n",
        "\n",
        "        assert isinstance(return_infobits, bool), 'return_info must be bool.'\n",
        "        self._return_infobits = return_infobits\n",
        "\n",
        "        assert isinstance(output_dtype, tf.DType), \\\n",
        "                                'output_dtype must be tf.DType.'\n",
        "        if output_dtype not in (tf.float16, tf.float32, tf.float64):\n",
        "            raise ValueError(\n",
        "                'output_dtype must be {tf.float16, tf.float32, tf.float64}.')\n",
        "        self._output_dtype = output_dtype\n",
        "\n",
        "        assert isinstance(stateful, bool), 'stateful must be bool.'\n",
        "        self._stateful = stateful\n",
        "\n",
        "        assert isinstance(prune_pcm, bool), 'prune_pcm must be bool.'\n",
        "        # prune punctured degree-1 VNs and connected CNs. A punctured\n",
        "        # VN-1 node will always \"send\" llr=0 to the connected CN. Thus, this\n",
        "        # CN will only send 0 messages to all other VNs, i.e., does not\n",
        "        # contribute to the decoding process.\n",
        "        self._prune_pcm = prune_pcm\n",
        "        if prune_pcm:\n",
        "            # find index of first position with only degree-1 VN\n",
        "            dv = np.sum(pcm, axis=0) # VN degree\n",
        "            last_pos = encoder._n_ldpc\n",
        "            for idx in range(encoder._n_ldpc-1, 0, -1):\n",
        "                if dv[0, idx]==1:\n",
        "                    last_pos = idx\n",
        "                else:\n",
        "                    break\n",
        "            # number of filler bits\n",
        "            k_filler = self.encoder.k_ldpc - self.encoder.k\n",
        "            # number of punctured bits\n",
        "            nb_punc_bits = ((self.encoder.n_ldpc - k_filler)\n",
        "                                     - self.encoder.n - 2*self.encoder.z)\n",
        "            # effective codeword length after pruning of vn-1 nodes\n",
        "            self._n_pruned = np.max((last_pos, encoder._n_ldpc - nb_punc_bits))\n",
        "            self._nb_pruned_nodes = encoder._n_ldpc - self._n_pruned\n",
        "            # remove last CNs and VNs from pcm\n",
        "            pcm = pcm[:-self._nb_pruned_nodes, :-self._nb_pruned_nodes]\n",
        "\n",
        "            #check for consistency\n",
        "            assert(self._nb_pruned_nodes>=0), \"Internal error: number of \\\n",
        "                        pruned nodes must be positive.\"\n",
        "        else:\n",
        "            self._nb_pruned_nodes = 0\n",
        "            # no pruning; same length as before\n",
        "            self._n_pruned = encoder._n_ldpc\n",
        "\n",
        "        # DECODER\n",
        "        super().__init__(pcm,\n",
        "                         trainable,\n",
        "                         cn_type,\n",
        "                         hard_out,\n",
        "                         track_exit,\n",
        "                         num_iter=num_iter,\n",
        "                         stateful=stateful,\n",
        "                         output_dtype=output_dtype,\n",
        "                         **kwargs)\n",
        "        # args.code.H = pcm\n",
        "        # self._decoder = Decoder(args)\n",
        "\n",
        "    #########################################\n",
        "    # Public methods and properties\n",
        "    #########################################\n",
        "\n",
        "    @property\n",
        "    def encoder(self):\n",
        "        \"\"\"LDPC Encoder used for rate-matching/recovery.\"\"\"\n",
        "        return self._encoder\n",
        "\n",
        "    #########################\n",
        "    # Keras layer functions\n",
        "    #########################\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"Build model.\"\"\"\n",
        "        if self._stateful:\n",
        "            assert(len(input_shape)==2), \\\n",
        "                \"For stateful decoding, a tuple of two inputs is expected.\"\n",
        "            input_shape = input_shape[0]\n",
        "\n",
        "        # check input dimensions for consistency\n",
        "        assert (input_shape[-1]==self.encoder.n), \\\n",
        "                                'Last dimension must be of length n.'\n",
        "        assert (len(input_shape)>=2), 'The inputs must have at least rank 2.'\n",
        "\n",
        "        self._old_shape_5g = input_shape\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Iterative BP decoding function.\n",
        "\n",
        "        This function performs ``num_iter`` belief propagation decoding\n",
        "        iterations and returns the estimated codeword.\n",
        "\n",
        "        Args:\n",
        "            inputs (tf.float32): Tensor of shape `[...,n]` containing the\n",
        "                channel logits/llr values.\n",
        "\n",
        "        Returns:\n",
        "            `tf.float32`: Tensor of shape `[...,n]` or `[...,k]`\n",
        "            (``return_infobits`` is True) containing bit-wise soft-estimates\n",
        "            (or hard-decided bit-values) of all codeword bits (or info\n",
        "            bits, respectively).\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If ``inputs`` is not of shape `[batch_size, n]`.\n",
        "\n",
        "            ValueError: If ``num_iter`` is not an integer greater (or equal)\n",
        "                `0`.\n",
        "\n",
        "            InvalidArgumentError: When rank(``inputs``)<2.\n",
        "        \"\"\"\n",
        "\n",
        "        # Extract inputs\n",
        "        if self._stateful:\n",
        "            llr_ch, msg_vn = inputs\n",
        "        else:\n",
        "            llr_ch = inputs\n",
        "\n",
        "        tf.debugging.assert_type(llr_ch, self.dtype, 'Invalid input dtype.')\n",
        "\n",
        "        llr_ch_shape = llr_ch.get_shape().as_list()\n",
        "        new_shape = [-1, llr_ch_shape[-1]]\n",
        "        llr_ch_reshaped = tf.reshape(llr_ch, new_shape)\n",
        "        batch_size = tf.shape(llr_ch_reshaped)[0]\n",
        "\n",
        "        # invert if rate-matching output interleaver was applied as defined in\n",
        "        # Sec. 5.4.2.2 in 38.212\n",
        "        if self._encoder.num_bits_per_symbol is not None:\n",
        "            llr_ch_reshaped = tf.gather(llr_ch_reshaped,\n",
        "                                        self._encoder.out_int_inv,\n",
        "                                        axis=-1)\n",
        "\n",
        "\n",
        "        # undo puncturing of the first 2*Z bit positions\n",
        "        llr_5g = tf.concat(\n",
        "            [tf.zeros([batch_size, 2*self.encoder.z], self._output_dtype),\n",
        "                          llr_ch_reshaped],\n",
        "                          1)\n",
        "\n",
        "        # undo puncturing of the last positions\n",
        "        # total length must be n_ldpc, while llr_ch has length n\n",
        "        # first 2*z positions are already added\n",
        "        # -> add n_ldpc - n - 2Z punctured positions\n",
        "        k_filler = self.encoder.k_ldpc - self.encoder.k # number of filler bits\n",
        "        nb_punc_bits = ((self.encoder.n_ldpc - k_filler)\n",
        "                                     - self.encoder.n - 2*self.encoder.z)\n",
        "\n",
        "\n",
        "        llr_5g = tf.concat([llr_5g,\n",
        "                   tf.zeros([batch_size, nb_punc_bits - self._nb_pruned_nodes],\n",
        "                            self._output_dtype)],\n",
        "                            1)\n",
        "\n",
        "        # undo shortening (= add 0 positions after k bits, i.e. LLR=LLR_max)\n",
        "        # the first k positions are the systematic bits\n",
        "        x1 = tf.slice(llr_5g, [0,0], [batch_size, self.encoder.k])\n",
        "\n",
        "        # parity part\n",
        "        nb_par_bits = (self.encoder.n_ldpc - k_filler\n",
        "                       - self.encoder.k - self._nb_pruned_nodes)\n",
        "        x2 = tf.slice(llr_5g,\n",
        "                      [0, self.encoder.k],\n",
        "                      [batch_size, nb_par_bits])\n",
        "\n",
        "        # negative sign due to logit definition\n",
        "        z = -tf.cast(self._llr_max, self._output_dtype) \\\n",
        "            * tf.ones([batch_size, k_filler], self._output_dtype)\n",
        "\n",
        "        llr_5g = tf.concat([x1, z, x2], 1)\n",
        "\n",
        "        return llr_5g\n",
        "\n",
        "        # ############################################################\n",
        "        # # and execute the decoder\n",
        "        # print(llr_5g.shape)\n",
        "        # x_hat = self._decoder(llr_5g) #super().call(llr_5g)\n",
        "        # ############################################################\n",
        "\n",
        "        # if self._return_infobits: # return only info bits\n",
        "        #     # reconstruct u_hat # code is systematic\n",
        "        #     u_hat = tf.slice(x_hat, [0,0], [batch_size, self.encoder.k])\n",
        "        #     # Reshape u_hat so that it matches the original input dimensions\n",
        "        #     output_shape = llr_ch_shape[0:-1] + [self.encoder.k]\n",
        "        #     # overwrite first dimension as this could be None (Keras)\n",
        "        #     output_shape[0] = -1\n",
        "        #     u_reshaped = tf.reshape(u_hat, output_shape)\n",
        "\n",
        "        #     # enable other output datatypes than tf.float32\n",
        "        #     u_out = tf.cast(u_reshaped, self._output_dtype)\n",
        "\n",
        "        #     if not self._stateful:\n",
        "        #         return u_out\n",
        "        #     else:\n",
        "        #         return u_out, msg_vn\n",
        "\n",
        "        # else: # return all codeword bits\n",
        "        #     # the transmitted CW bits are not the same as used during decoding\n",
        "        #     # cf. last parts of 5G encoding function\n",
        "\n",
        "        #     # remove last dim\n",
        "        #     x = tf.reshape(x_hat, [batch_size, self._n_pruned])\n",
        "\n",
        "        #     # remove filler bits at pos (k, k_ldpc)\n",
        "        #     x_no_filler1 = tf.slice(x, [0, 0], [batch_size, self.encoder.k])\n",
        "\n",
        "        #     x_no_filler2 = tf.slice(x,\n",
        "        #                             [0, self.encoder.k_ldpc],\n",
        "        #                             [batch_size,\n",
        "        #                             self._n_pruned-self.encoder.k_ldpc])\n",
        "\n",
        "        #     x_no_filler = tf.concat([x_no_filler1, x_no_filler2], 1)\n",
        "\n",
        "        #     # shorten the first 2*Z positions and end after n bits\n",
        "        #     x_short = tf.slice(x_no_filler,\n",
        "        #                        [0, 2*self.encoder.z],\n",
        "        #                        [batch_size, self.encoder.n])\n",
        "\n",
        "        #     # if used, apply rate-matching output interleaver again as\n",
        "        #     # Sec. 5.4.2.2 in 38.212\n",
        "        #     if self._encoder.num_bits_per_symbol is not None:\n",
        "        #         x_short = tf.gather(x_short, self._encoder.out_int, axis=-1)\n",
        "\n",
        "        #     # Reshape x_short so that it matches the original input dimensions\n",
        "        #     # overwrite first dimension as this could be None (Keras)\n",
        "        #     llr_ch_shape[0] = -1\n",
        "        #     x_short= tf.reshape(x_short, llr_ch_shape)\n",
        "\n",
        "        #     # enable other output datatypes than tf.float32\n",
        "        #     x_out = tf.cast(x_short, self._output_dtype)\n",
        "\n",
        "        #     if not self._stateful:\n",
        "        #         return x_out\n",
        "        #     else:\n",
        "        #         return x_out, msg_vn"
      ],
      "metadata": {
        "id": "V9QZfziI_GzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## DATA ###\n",
        "EbNo_range_train = range(2, 8)\n",
        "EbNo_range_test = range(5, 14)\n",
        "# Standard deviation for train/test\n",
        "std_train = [EbN0_to_std(ii, args.k / args.n) for ii in EbNo_range_train]\n",
        "std_test = [EbN0_to_std(ii, args.k / args.n) for ii in EbNo_range_test]\n",
        "\n",
        "scheduler = tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate=args.lr, decay_steps=args.epochs) # 1000 is size of trainloader\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=scheduler)\n",
        "\n",
        "train_loader = FEC_Dataset(args.code, sigma=std_test, zero_cw=True, length=args.traindata_len).batch(args.batch_size).shuffle(buffer_size=args.batch_size)\n",
        "\n",
        "#                         z_cw   m 1s   1-cw     Should use zero codeword by default\n",
        "dataset_types = {\n",
        "              \"bin_bits\":(False, False, False), # Binary bits sent and recieved with some awgn\n",
        "              \"flip_cw\": (True, False, True),   # Zero codeword flipped to a all ones vector [1,1,...,1]\n",
        "              \"zero_cw\": (True, False, False),  # Standard zero codeword used for training\n",
        "              \"ones_m\":  (False, True, False),  # Makes the message all ones vector and passes it to generator matrix producing codeword and pcm\n",
        "              }\n",
        "\n",
        "test_ebnos_datasets = [ [FEC_Dataset(args.code, sigma=std_test, zero_cw=zero_cw, ones_m=ones_m, flip_cw=flip_cw)\n",
        "                                 for ii in range(len(std_test))]\n",
        "                                 for (zero_cw, ones_m, flip_cw) in dataset_types.values() ]"
      ],
      "metadata": {
        "id": "j7E0LIaj0YrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    print(\"Training Linear Transformer Diffusion Model...\")\n",
        "    # train_dec(dec, train_loader, optimizer, epoch,\n",
        "    #           LR=scheduler(tf.Variable(0, dtype=tf.float32)).numpy(),\n",
        "    #           traindata_len=args.traindata_len)\n",
        "\n",
        "    # print comparison\n",
        "    if epoch % 1 == 0:\n",
        "        data = test_models(dec, test_ebnos_datasets, EbNo_range_test)\n",
        "    break # from for loop\n",
        "\n",
        "data"
      ],
      "metadata": {
        "id": "tO8H1C_U2XDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9mzuvXAlGLX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_comparison(title, EbNo_range, ber, fer, diff_iters):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot diff_iters to decoding\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(EbNo_range, diff_iters, marker='o', label='diff_iters to decode', color='blue')\n",
        "    plt.yscale('log')\n",
        "    plt.xlabel('Eb/No (dB)')\n",
        "    plt.ylabel('diff_iters to decode')\n",
        "    plt.title('diff_iters to decode vs Eb/No')\n",
        "    plt.grid(True, which=\"both\", ls=\"--\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot BER for both models\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(EbNo_range, ber, marker='x', label='BER', color='green')\n",
        "    plt.yscale('log')\n",
        "    plt.xlabel('Eb/No (dB)')\n",
        "    plt.ylabel('BER')\n",
        "    plt.title('BER vs Eb/No')\n",
        "    plt.grid(True, which=\"both\", ls=\"--\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot FER for both models\n",
        "    plt.subplot(1, 2, 3)\n",
        "    plt.plot(EbNo_range, fer, marker='o', label='FER', color='red')\n",
        "    plt.yscale('log')\n",
        "    plt.xlabel('Eb/No (dB)')\n",
        "    plt.ylabel('FER')\n",
        "    plt.title('FER vs Eb/No')\n",
        "    plt.grid(True, which=\"both\", ls=\"--\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Set the overall title for the figure\n",
        "    plt.suptitle(title)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "for ix, dataset_type in enumerate(dataset_types.keys()):\n",
        "    ber = data['LTDM'][ix]['ber']\n",
        "    fer = data['LTDM'][ix]['bler']\n",
        "    diff_iters = data['LTDM'][ix]['diff_iters']\n",
        "\n",
        "    plot_comparison(dataset_type.upper(), EbNo_range_test, ber, fer, diff_iters)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVUuNxZ4eFhtnowNynybLx",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}