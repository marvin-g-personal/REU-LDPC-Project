{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pollyjuice74/REU-LDPC-Project/blob/main/DDECCT_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_k_fbfIf91j"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils import data\n",
        "from datetime import datetime\n",
        "import time\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "!git clone https://github.com/pollyjuice74/gnn-decoder\n",
        "!pip install sionna\n",
        "\n",
        "if os.path.exists('gnn-decoder'):\n",
        "  os.rename('gnn-decoder', 'gnn_decoder')\n",
        "\n",
        "from gnn_decoder.gnn import GNN_BP\n",
        "\n",
        "if not os.path.exists('DDECC'):\n",
        "  !git clone https://github.com/pollyjuice74/DDECC.git\n",
        "os.chdir('DDECC')\n",
        "\n",
        "from Codes import *\n",
        "from DDECC import *\n",
        "from utils import *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The modifications are made so that the model trains on BCH codes of length n=63, k=45, where it says:\n",
        "\n",
        "\"### IMPORTANT ###\""
      ],
      "metadata": {
        "id": "pGW0jSfZQ5vg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The modifications made are seen in the **FEC_Dataset** where it says:\n",
        "\n",
        "\"### IMPORTANT ###\""
      ],
      "metadata": {
        "id": "cc9SRvk2QS3a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QXuKlYv-n6Vj"
      },
      "outputs": [],
      "source": [
        "############ ZERO CODEWORD SET TO TRUE ###############\n",
        "class FEC_Dataset(data.Dataset):                 ####\n",
        "    def __init__(self, code, sigma, len, zero_cw=True):\n",
        "        self.code = code\n",
        "        self.sigma = sigma\n",
        "        self.len = len\n",
        "        self.generator_matrix = code.generator_matrix.transpose(0, 1)\n",
        "        self.pc_matrix = code.pc_matrix.transpose(0, 1)\n",
        "\n",
        "        self.zero_word = torch.zeros((self.code.k)).long() if zero_cw else None\n",
        "        self.zero_cw = torch.zeros((self.code.n)).long() if zero_cw else None\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.zero_cw is None:\n",
        "            m = torch.randint(0, 2, (1, self.code.k)).squeeze()\n",
        "            x = torch.matmul(m, self.generator_matrix) % 2\n",
        "        else: # SET TO TRUE\n",
        "            m = self.zero_word\n",
        "            x = self.zero_cw\n",
        "\n",
        "        std_noise = random.choice(self.sigma)\n",
        "        z = torch.randn(self.code.n) * std_noise\n",
        "        #h = torch.from_numpy(np.random.rayleigh(1,self.code.n)).float()\n",
        "        # y = x.clone()\n",
        "\n",
        "        # # index to be flipped\n",
        "        # ix = torch.tensor(random.sample(range(self.code.n), 3))\n",
        "        # y[ix] = 1 - y[ix] # flip bits\n",
        "        # y = bin_to_sign(y)\n",
        "\n",
        "        ### IMPORTANT ###\n",
        "        #######################################################################\n",
        "        #######################################################################\n",
        "\n",
        "        h=1\n",
        "        y = h*bin_to_sign(x) + z\n",
        "\n",
        "        std_noise = random.choice(self.sigma)\n",
        "        noise_variance = std_noise ** 2\n",
        "\n",
        "        # y to llrs\n",
        "        llr = 2 * y / noise_variance\n",
        "        #######################################################################\n",
        "        #######################################################################\n",
        "\n",
        "        magnitude = torch.abs(y)\n",
        "        syndrome = torch.matmul(sign_to_bin(torch.sign(y)).long(),\n",
        "                                self.pc_matrix) % 2\n",
        "        syndrome = bin_to_sign(syndrome)\n",
        "        return m.float(), x.float(), z.float(), y.float(), llr.float(), magnitude.float(), syndrome.float()\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch, LR):\n",
        "    model.train()\n",
        "    cum_loss = cum_samples = 0\n",
        "    t = time.time()\n",
        "    for batch_idx, (m, x, z, y, llr, magnitude, syndrome) in enumerate(\n",
        "            train_loader):\n",
        "        loss = model.loss(bin_to_sign(x))\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        model.ema.update(model)\n",
        "        ###\n",
        "        cum_loss += loss.item() * x.shape[0]\n",
        "        cum_samples += x.shape[0]\n",
        "        if (batch_idx+1) % 500 == 0 or batch_idx == len(train_loader) - 1:\n",
        "            print(\n",
        "                f'Training epoch {epoch}, Batch {batch_idx + 1}/{len(train_loader)}: LR={LR:.2e}, Loss={cum_loss / cum_samples:.5e}')\n",
        "    print(f'Epoch {epoch} Train Time {time.time() - t}s\\n')\n",
        "    return cum_loss / cum_samples\n",
        "\n",
        "\n",
        "def test(model, device, test_loader_list, EbNo_range_test, min_FER=100, max_cum_count=1e7, min_cum_count=1e5):\n",
        "    model.eval()\n",
        "    test_loss_ber_list, test_loss_fer_list, cum_samples_all = [], [], []\n",
        "    t = time.time()\n",
        "    with torch.no_grad():\n",
        "        for ii, test_loader in enumerate(test_loader_list):\n",
        "            test_ber = test_fer = cum_count = 0.\n",
        "            _, x_pred_list, _, _ = model.p_sample_loop(next(iter(test_loader))[3])\n",
        "            test_ber_ddpm , test_fer_ddpm = [0]*len(x_pred_list), [0]*len(x_pred_list)\n",
        "            idx_conv_all = []\n",
        "            while True:\n",
        "                (m, x, z, y, magnitude, syndrome) = next(iter(test_loader))\n",
        "                x_pred, x_pred_list, idx_conv,synd_all = model.p_sample_loop(y)\n",
        "                x_pred = sign_to_bin(torch.sign(x_pred))\n",
        "\n",
        "                idx_conv_all.append(idx_conv)\n",
        "                for kk, x_pred_tmp in enumerate(x_pred_list):\n",
        "                    x_pred_tmp = sign_to_bin(torch.sign(x_pred_tmp))\n",
        "\n",
        "                    test_ber_ddpm[kk] += BER(x_pred_tmp, x) * x.shape[0]\n",
        "                    test_fer_ddpm[kk] += FER(x_pred_tmp, x) * x.shape[0]\n",
        "\n",
        "                test_ber += BER(x_pred, x) * x.shape[0]\n",
        "                test_fer += FER(x_pred, x) * x.shape[0]\n",
        "                cum_count += x.shape[0]\n",
        "                if (min_FER > 0 and test_fer > min_FER and cum_count > min_cum_count) or cum_count >= max_cum_count:\n",
        "                    if cum_count >= 1e9:\n",
        "                        print(f'Cum count reached EbN0:{EbNo_range_test[ii]}')\n",
        "                    else:\n",
        "                        print(f'FER count treshold reached EbN0:{EbNo_range_test[ii]}')\n",
        "                    break\n",
        "            idx_conv_all = torch.stack(idx_conv_all).float()\n",
        "            cum_samples_all.append(cum_count)\n",
        "            test_loss_ber_list.append(test_ber / cum_count)\n",
        "            test_loss_fer_list.append(test_fer / cum_count)\n",
        "            for kk in range(len(test_ber_ddpm)):\n",
        "                test_ber_ddpm[kk] /= cum_count\n",
        "                test_fer_ddpm[kk] /= cum_count\n",
        "            print(f'Test EbN0={EbNo_range_test[ii]}, BER={test_loss_ber_list}')\n",
        "            print(f'Test EbN0={EbNo_range_test[ii]}, BER_DDPM={test_ber_ddpm}')\n",
        "            print(f'Test EbN0={EbNo_range_test[ii]}, -ln(BER)_DDPM={[-np.log(elem) for elem in test_ber_ddpm]}')\n",
        "            print(f'Test EbN0={EbNo_range_test[ii]}, FER_DDPM={test_fer_ddpm}')\n",
        "            print(f'#It. to zero syndrome: Mean={idx_conv_all.mean()}, Std={idx_conv_all.std()}, Min={idx_conv_all.min()}, Max={idx_conv_all.max()}')\n",
        "        ###\n",
        "        print('Test FER ' + ' '.join(\n",
        "            ['{}: {:.2e}'.format(ebno, elem) for (elem, ebno)\n",
        "             in\n",
        "             (zip(test_loss_fer_list, EbNo_range_test))]))\n",
        "        print('Test BER ' + ' '.join(\n",
        "            ['{}: {:.2e}'.format(ebno, elem) for (elem, ebno)\n",
        "             in\n",
        "             (zip(test_loss_ber_list, EbNo_range_test))]))\n",
        "        print('Test -ln(BER) ' + ' '.join(\n",
        "            ['{}: {:.2e}'.format(ebno, -np.log(elem)) for (elem, ebno)\n",
        "             in\n",
        "             (zip(test_loss_ber_list, EbNo_range_test))]))\n",
        "    print(f'# of testing samples: {cum_samples_all}\\n Test Time {time.time() - t} s\\n')\n",
        "    return test_loss_ber_list, test_loss_fer_list\n",
        "\n",
        "\n",
        "\n",
        "# model = DDECCT(args, device=device,dropout=0).to(device)\n",
        "# model.ema.register(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "f4VhjwNEljG3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fc746d87-c9b6-478a-9d65-6d4f422f92cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[False,  True,  True,  ...,  True,  True,  True],\n",
            "          [ True, False,  True,  ...,  True,  True,  True],\n",
            "          [ True,  True, False,  ...,  True,  True,  True],\n",
            "          ...,\n",
            "          [ True,  True,  True,  ..., False,  True,  True],\n",
            "          [ True,  True,  True,  ...,  True, False,  True],\n",
            "          [ True,  True,  True,  ...,  True,  True, False]]]])\n",
            "DDECCT(\n",
            "  (decoder): Encoder(\n",
            "    (layers): ModuleList(\n",
            "      (0-1): 2 x EncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0-3): 4 x Linear(in_features=32, out_features=32, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
            "          (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
            "          (dropout): Dropout(p=0, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0-1): 2 x SublayerConnection(\n",
            "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "    (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (oned_final_embed): Sequential(\n",
            "    (0): Linear(in_features=32, out_features=1, bias=True)\n",
            "  )\n",
            "  (out_fc): Linear(in_features=81, out_features=63, bias=True)\n",
            "  (time_embed): Embedding(23, 32)\n",
            ")\n",
            "# of Parameters: 34063\n",
            "Training model with code type: BCH\n",
            "BCH\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DDECC Loss\n",
            "x_0:  torch.Size([128, 63])\n",
            "t:  torch.Size([65])\n",
            "t:  torch.Size([128])\n",
            "e:  torch.Size([128, 63])\n",
            "noise_factor:  torch.Size([128, 1])\n",
            "h:  torch.Size([63])\n",
            "yt:  torch.Size([128, 63])\n",
            "sum_syndrome:  torch.Size([128])\n",
            "\n",
            "DDECCT model\n",
            "magnitude:  torch.Size([128, 63])\n",
            "syndrome:  torch.Size([128, 18]) tensor([[ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1., -1.,  1.,  ..., -1., -1.,  1.],\n",
            "        [ 1., -1., -1.,  ...,  1., -1., -1.],\n",
            "        ...,\n",
            "        [ 1.,  1.,  1.,  ..., -1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.]])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "time_emb:  torch.Size([128, 1, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "out_fc:  torch.Size([128, 63]) tensor([[ 1.1049,  0.3087,  0.1041,  ...,  0.1831,  1.1800,  0.4571],\n",
            "        [ 0.8460, -1.2810, -0.3899,  ...,  0.6222,  0.9290, -0.2577],\n",
            "        [ 0.3626,  1.1882,  0.0508,  ..., -2.5425,  0.4151,  2.8715],\n",
            "        ...,\n",
            "        [ 1.0635,  1.1428, -0.6710,  ..., -1.4067, -1.0958,  0.4206],\n",
            "        [ 1.0754,  0.3122,  0.1934,  ...,  0.1987,  1.1554,  0.3968],\n",
            "        [ 1.0153,  0.2694,  0.1099,  ...,  0.2010,  1.2387,  0.4065]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "output:  torch.Size([128, 63])\n",
            "z_mul:  torch.Size([128, 63])\n",
            "\n",
            "DDECC Loss\n",
            "x_0:  torch.Size([128, 63])\n",
            "t:  torch.Size([65])\n",
            "t:  torch.Size([128])\n",
            "e:  torch.Size([128, 63])\n",
            "noise_factor:  torch.Size([128, 1])\n",
            "h:  torch.Size([63])\n",
            "yt:  torch.Size([128, 63])\n",
            "sum_syndrome:  torch.Size([128])\n",
            "\n",
            "DDECCT model\n",
            "magnitude:  torch.Size([128, 63])\n",
            "syndrome:  torch.Size([128, 18]) tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        ...,\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.]])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "time_emb:  torch.Size([128, 1, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "out_fc:  torch.Size([128, 63]) tensor([[ 0.9586, -0.1899, -0.0798,  ...,  0.8141,  0.9131, -0.2564],\n",
            "        [ 0.9198,  0.0807, -0.0447,  ...,  0.9232,  1.0007, -0.4332],\n",
            "        [ 0.8384,  0.0878, -0.0181,  ...,  0.7999,  1.0716, -0.3879],\n",
            "        ...,\n",
            "        [ 0.8467,  0.3457,  0.0213,  ...,  0.8115,  0.8756, -0.5395],\n",
            "        [ 0.8944,  0.1236, -0.0549,  ...,  0.8363,  1.0130, -0.4122],\n",
            "        [ 0.8769,  0.1477, -0.0273,  ...,  0.8876,  0.9945, -0.3923]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "output:  torch.Size([128, 63])\n",
            "z_mul:  torch.Size([128, 63])\n",
            "\n",
            "DDECC Loss\n",
            "x_0:  torch.Size([128, 63])\n",
            "t:  torch.Size([65])\n",
            "t:  torch.Size([128])\n",
            "e:  torch.Size([128, 63])\n",
            "noise_factor:  torch.Size([128, 1])\n",
            "h:  torch.Size([63])\n",
            "yt:  torch.Size([128, 63])\n",
            "sum_syndrome:  torch.Size([128])\n",
            "\n",
            "DDECCT model\n",
            "magnitude:  torch.Size([128, 63])\n",
            "syndrome:  torch.Size([128, 18]) tensor([[ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        ...,\n",
            "        [-1.,  1., -1.,  ...,  1.,  1., -1.],\n",
            "        [-1.,  1., -1.,  ..., -1.,  1., -1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.]])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "time_emb:  torch.Size([128, 1, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "out_fc:  torch.Size([128, 63]) tensor([[ 0.2386,  1.0922, -0.4358,  ..., -0.6361,  0.6811,  0.9088],\n",
            "        [ 0.5564,  0.1450, -0.3954,  ...,  0.7406,  0.5573, -0.3851],\n",
            "        [ 0.5732,  0.0742, -0.3305,  ...,  0.9041,  0.6339, -0.4760],\n",
            "        ...,\n",
            "        [ 0.0862, -0.8499,  1.1259,  ...,  1.4902, -0.4337, -2.5414],\n",
            "        [ 0.9835, -0.6425,  0.8377,  ...,  0.3075,  0.7931, -1.7703],\n",
            "        [ 0.5361,  0.0979, -0.2502,  ...,  0.8940,  0.6712, -0.4486]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "output:  torch.Size([128, 63])\n",
            "z_mul:  torch.Size([128, 63])\n",
            "\n",
            "DDECC Loss\n",
            "x_0:  torch.Size([128, 63])\n",
            "t:  torch.Size([65])\n",
            "t:  torch.Size([128])\n",
            "e:  torch.Size([128, 63])\n",
            "noise_factor:  torch.Size([128, 1])\n",
            "h:  torch.Size([63])\n",
            "yt:  torch.Size([128, 63])\n",
            "sum_syndrome:  torch.Size([128])\n",
            "\n",
            "DDECCT model\n",
            "magnitude:  torch.Size([128, 63])\n",
            "syndrome:  torch.Size([128, 18]) tensor([[ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        ...,\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1., -1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.]])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "time_emb:  torch.Size([128, 1, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "out_fc:  torch.Size([128, 63]) tensor([[ 0.3884,  0.1438, -0.5156,  ...,  0.4813,  0.1733, -0.1484],\n",
            "        [ 0.2777,  0.1631, -0.5635,  ...,  0.5687,  0.1969, -0.1403],\n",
            "        [ 0.1607,  0.0613, -0.5317,  ...,  0.6143,  0.1723, -0.3475],\n",
            "        ...,\n",
            "        [ 0.3132,  0.2417, -0.5270,  ...,  0.5164,  0.2180, -0.1577],\n",
            "        [-0.2091,  0.5132, -0.0038,  ...,  0.8236, -1.6288, -2.2874],\n",
            "        [ 0.2620,  0.0726, -0.5173,  ...,  0.6003,  0.1069, -0.1691]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "output:  torch.Size([128, 63])\n",
            "z_mul:  torch.Size([128, 63])\n",
            "\n",
            "DDECC Loss\n",
            "x_0:  torch.Size([128, 63])\n",
            "t:  torch.Size([65])\n",
            "t:  torch.Size([128])\n",
            "e:  torch.Size([128, 63])\n",
            "noise_factor:  torch.Size([128, 1])\n",
            "h:  torch.Size([63])\n",
            "yt:  torch.Size([128, 63])\n",
            "sum_syndrome:  torch.Size([128])\n",
            "\n",
            "DDECCT model\n",
            "magnitude:  torch.Size([128, 63])\n",
            "syndrome:  torch.Size([128, 18]) tensor([[ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [-1.,  1., -1.,  ...,  1., -1., -1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        ...,\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1., -1.,  ...,  1.,  1., -1.]])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "time_emb:  torch.Size([128, 1, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "out_fc:  torch.Size([128, 63]) tensor([[ 0.0060,  0.2622, -0.7833,  ...,  0.2158, -0.2456,  0.2293],\n",
            "        [-0.0493, -1.4026, -0.9823,  ...,  0.8917, -0.8482, -0.5139],\n",
            "        [-0.0517,  0.3690, -0.6320,  ..., -0.0231, -0.2731,  0.4117],\n",
            "        ...,\n",
            "        [-0.0269,  0.3067, -0.8368,  ...,  0.0415, -0.3653,  0.2653],\n",
            "        [ 0.0283,  0.2686, -0.8237,  ...,  0.2182, -0.2596,  0.2519],\n",
            "        [ 0.1362, -0.5577,  0.3412,  ...,  0.9385,  0.0434, -3.1699]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "output:  torch.Size([128, 63])\n",
            "z_mul:  torch.Size([128, 63])\n",
            "\n",
            "DDECC Loss\n",
            "x_0:  torch.Size([128, 63])\n",
            "t:  torch.Size([65])\n",
            "t:  torch.Size([128])\n",
            "e:  torch.Size([128, 63])\n",
            "noise_factor:  torch.Size([128, 1])\n",
            "h:  torch.Size([63])\n",
            "yt:  torch.Size([128, 63])\n",
            "sum_syndrome:  torch.Size([128])\n",
            "\n",
            "DDECCT model\n",
            "magnitude:  torch.Size([128, 63])\n",
            "syndrome:  torch.Size([128, 18]) tensor([[ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        ...,\n",
            "        [-1., -1.,  1.,  ..., -1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.]])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "time_emb:  torch.Size([128, 1, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "out_fc:  torch.Size([128, 63]) tensor([[-0.2980,  0.3596, -0.9640,  ..., -0.0496, -0.5858,  0.4557],\n",
            "        [-0.2452,  0.3233, -0.9291,  ..., -0.0083, -0.6116,  0.4808],\n",
            "        [ 0.2695, -0.1562, -0.9464,  ..., -0.0157, -0.7247,  0.4580],\n",
            "        ...,\n",
            "        [ 0.0536, -0.5948,  0.0378,  ...,  0.3326, -1.0647, -0.8694],\n",
            "        [-0.1935,  0.3863, -0.9738,  ...,  0.1590, -0.4564,  0.3554],\n",
            "        [-0.1826,  0.2949, -0.9599,  ..., -0.0177, -0.5792,  0.4350]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "output:  torch.Size([128, 63])\n",
            "z_mul:  torch.Size([128, 63])\n",
            "\n",
            "DDECC Loss\n",
            "x_0:  torch.Size([128, 63])\n",
            "t:  torch.Size([65])\n",
            "t:  torch.Size([128])\n",
            "e:  torch.Size([128, 63])\n",
            "noise_factor:  torch.Size([128, 1])\n",
            "h:  torch.Size([63])\n",
            "yt:  torch.Size([128, 63])\n",
            "sum_syndrome:  torch.Size([128])\n",
            "\n",
            "DDECCT model\n",
            "magnitude:  torch.Size([128, 63])\n",
            "syndrome:  torch.Size([128, 18]) tensor([[ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        ...,\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ..., -1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.]])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "time_emb:  torch.Size([128, 1, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "out_fc:  torch.Size([128, 63]) tensor([[ 0.9373,  0.9165, -0.7857,  ...,  0.1051,  0.4249,  0.8872],\n",
            "        [-0.4698,  0.3769, -1.0474,  ..., -0.1139, -0.9243,  0.4252],\n",
            "        [-0.5541,  0.3284, -1.0189,  ..., -0.0139, -0.8697,  0.3664],\n",
            "        ...,\n",
            "        [-0.5399,  0.3745, -1.0712,  ..., -0.0949, -0.8953,  0.4105],\n",
            "        [ 0.8817,  0.9829, -1.0503,  ..., -0.2727,  0.2388,  1.1083],\n",
            "        [-0.4942,  0.3582, -1.0939,  ..., -0.1036, -0.9421,  0.4732]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "output:  torch.Size([128, 63])\n",
            "z_mul:  torch.Size([128, 63])\n",
            "\n",
            "DDECC Loss\n",
            "x_0:  torch.Size([128, 63])\n",
            "t:  torch.Size([65])\n",
            "t:  torch.Size([128])\n",
            "e:  torch.Size([128, 63])\n",
            "noise_factor:  torch.Size([128, 1])\n",
            "h:  torch.Size([63])\n",
            "yt:  torch.Size([128, 63])\n",
            "sum_syndrome:  torch.Size([128])\n",
            "\n",
            "DDECCT model\n",
            "magnitude:  torch.Size([128, 63])\n",
            "syndrome:  torch.Size([128, 18]) tensor([[ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [-1.,  1., -1.,  ..., -1., -1., -1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        ...,\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.]])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "time_emb:  torch.Size([128, 1, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "out_fc:  torch.Size([128, 63]) tensor([[-0.6972,  0.3017, -1.2731,  ..., -0.0757, -1.1544,  0.2153],\n",
            "        [-0.1582, -0.4539,  0.1325,  ...,  0.8332, -0.4044, -2.0937],\n",
            "        [-0.6505,  0.2431, -1.3441,  ...,  0.1973, -1.1457,  0.0483],\n",
            "        ...,\n",
            "        [-0.6782,  0.4029, -1.3337,  ..., -0.0077, -1.2072,  0.3284],\n",
            "        [-0.6396,  0.3374, -1.2581,  ..., -0.0785, -1.1785,  0.3083],\n",
            "        [-0.5660,  0.3371, -1.2698,  ...,  0.0359, -1.1594,  0.2674]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "output:  torch.Size([128, 63])\n",
            "z_mul:  torch.Size([128, 63])\n",
            "\n",
            "DDECC Loss\n",
            "x_0:  torch.Size([128, 63])\n",
            "t:  torch.Size([65])\n",
            "t:  torch.Size([128])\n",
            "e:  torch.Size([128, 63])\n",
            "noise_factor:  torch.Size([128, 1])\n",
            "h:  torch.Size([63])\n",
            "yt:  torch.Size([128, 63])\n",
            "sum_syndrome:  torch.Size([128])\n",
            "\n",
            "DDECCT model\n",
            "magnitude:  torch.Size([128, 63])\n",
            "syndrome:  torch.Size([128, 18]) tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        ...,\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.]])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "time_emb:  torch.Size([128, 1, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "out_fc:  torch.Size([128, 63]) tensor([[-0.7957,  0.4596, -1.4376,  ..., -0.1888, -0.7994,  0.0989],\n",
            "        [-0.8630,  0.3422, -1.3540,  ..., -0.0368, -1.4261,  0.0989],\n",
            "        [-0.8214,  0.1855, -1.4776,  ...,  0.0172, -1.4754,  0.1038],\n",
            "        ...,\n",
            "        [-0.8580,  0.3088, -1.4079,  ..., -0.0459, -1.3831,  0.0638],\n",
            "        [-0.8577,  0.2503, -1.4767,  ...,  0.0030, -1.3621,  0.0550],\n",
            "        [-1.0212,  0.0521, -1.5718,  ...,  0.2022, -1.6926, -0.3063]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "output:  torch.Size([128, 63])\n",
            "z_mul:  torch.Size([128, 63])\n",
            "\n",
            "DDECC Loss\n",
            "x_0:  torch.Size([128, 63])\n",
            "t:  torch.Size([65])\n",
            "t:  torch.Size([128])\n",
            "e:  torch.Size([128, 63])\n",
            "noise_factor:  torch.Size([128, 1])\n",
            "h:  torch.Size([63])\n",
            "yt:  torch.Size([128, 63])\n",
            "sum_syndrome:  torch.Size([128])\n",
            "\n",
            "DDECCT model\n",
            "magnitude:  torch.Size([128, 63])\n",
            "syndrome:  torch.Size([128, 18]) tensor([[ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1., -1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        ...,\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.]])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "time_emb:  torch.Size([128, 1, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "out_fc:  torch.Size([128, 63]) tensor([[-0.9526,  0.1847, -1.4702,  ...,  0.0315, -1.4034, -0.2253],\n",
            "        [ 0.1257, -1.1643,  0.6634,  ...,  1.1939, -0.4748, -2.6785],\n",
            "        [-1.0427,  0.1801, -1.6579,  ...,  0.0149, -1.5849, -0.1520],\n",
            "        ...,\n",
            "        [-1.1213,  0.1885, -1.5961,  ..., -0.0786, -1.5747, -0.0490],\n",
            "        [-0.9931,  0.3831, -1.4609,  ...,  0.1203, -1.5407, -0.0222],\n",
            "        [-0.9894,  0.1891, -1.6256,  ..., -0.0105, -1.6231, -0.1363]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "output:  torch.Size([128, 63])\n",
            "z_mul:  torch.Size([128, 63])\n",
            "\n",
            "DDECC Loss\n",
            "x_0:  torch.Size([128, 63])\n",
            "t:  torch.Size([65])\n",
            "t:  torch.Size([128])\n",
            "e:  torch.Size([128, 63])\n",
            "noise_factor:  torch.Size([128, 1])\n",
            "h:  torch.Size([63])\n",
            "yt:  torch.Size([128, 63])\n",
            "sum_syndrome:  torch.Size([128])\n",
            "\n",
            "DDECCT model\n",
            "magnitude:  torch.Size([128, 63])\n",
            "syndrome:  torch.Size([128, 18]) tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        ...,\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.]])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "time_emb:  torch.Size([128, 1, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "out_fc:  torch.Size([128, 63]) tensor([[-1.1891, -0.1525, -2.0685,  ..., -0.2900, -2.3325, -0.2693],\n",
            "        [-1.2300,  0.0653, -1.9453,  ..., -0.0614, -1.8706, -0.2612],\n",
            "        [ 1.3831,  0.7616, -0.8849,  ...,  0.0778,  0.7182,  0.4147],\n",
            "        ...,\n",
            "        [-1.2201,  0.0939, -1.9606,  ..., -0.0775, -1.8920, -0.2273],\n",
            "        [-1.3659,  0.1035, -1.6395,  ..., -0.2755, -1.7521, -0.1721],\n",
            "        [-1.2464,  0.1518, -1.8192,  ..., -0.0505, -1.8590, -0.2859]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "output:  torch.Size([128, 63])\n",
            "z_mul:  torch.Size([128, 63])\n",
            "\n",
            "DDECC Loss\n",
            "x_0:  torch.Size([128, 63])\n",
            "t:  torch.Size([65])\n",
            "t:  torch.Size([128])\n",
            "e:  torch.Size([128, 63])\n",
            "noise_factor:  torch.Size([128, 1])\n",
            "h:  torch.Size([63])\n",
            "yt:  torch.Size([128, 63])\n",
            "sum_syndrome:  torch.Size([128])\n",
            "\n",
            "DDECCT model\n",
            "magnitude:  torch.Size([128, 63])\n",
            "syndrome:  torch.Size([128, 18]) tensor([[ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        ...,\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [-1.,  1., -1.,  ..., -1., -1., -1.],\n",
            "        [ 1., -1., -1.,  ...,  1.,  1., -1.]])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "time_emb:  torch.Size([128, 1, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "out_fc:  torch.Size([128, 63]) tensor([[-1.4500,  0.0537, -2.1076,  ..., -0.1987, -2.1217, -0.3063],\n",
            "        [-1.4663,  0.1166, -2.0999,  ..., -0.2140, -2.0898, -0.2898],\n",
            "        [-1.4889,  0.0824, -2.0679,  ..., -0.1870, -2.1146, -0.3380],\n",
            "        ...,\n",
            "        [-1.4767,  0.1157, -2.0783,  ..., -0.0984, -2.1344, -0.3649],\n",
            "        [-0.9103,  1.2645, -0.3289,  ...,  0.4223, -0.8415, -0.4407],\n",
            "        [-0.7841,  2.5250, -2.0338,  ..., -0.7839,  0.3017,  0.2391]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "output:  torch.Size([128, 63])\n",
            "z_mul:  torch.Size([128, 63])\n",
            "\n",
            "DDECC Loss\n",
            "x_0:  torch.Size([128, 63])\n",
            "t:  torch.Size([65])\n",
            "t:  torch.Size([128])\n",
            "e:  torch.Size([128, 63])\n",
            "noise_factor:  torch.Size([128, 1])\n",
            "h:  torch.Size([63])\n",
            "yt:  torch.Size([128, 63])\n",
            "sum_syndrome:  torch.Size([128])\n",
            "\n",
            "DDECCT model\n",
            "magnitude:  torch.Size([128, 63])\n",
            "syndrome:  torch.Size([128, 18]) tensor([[ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [-1., -1., -1.,  ..., -1.,  1., -1.],\n",
            "        ...,\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1., -1.,  ...,  1.,  1., -1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.]])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "time_emb:  torch.Size([128, 1, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "out_fc:  torch.Size([128, 63]) tensor([[-1.6958e+00, -3.4435e-03, -2.2866e+00,  ..., -4.0098e-01,\n",
            "         -2.3688e+00, -3.3449e-01],\n",
            "        [-1.6505e+00,  1.8068e-02, -2.3181e+00,  ..., -3.2432e-01,\n",
            "         -2.4331e+00, -3.4694e-01],\n",
            "        [-8.7011e-01,  1.5503e+00, -2.4362e+00,  ..., -5.0770e-01,\n",
            "          2.0112e-01, -4.7311e-01],\n",
            "        ...,\n",
            "        [ 1.3587e+00,  7.2384e-01, -9.4697e-01,  ..., -9.2672e-02,\n",
            "          6.2432e-01,  2.6445e-01],\n",
            "        [-4.1453e-01, -5.3389e-01,  1.9751e-02,  ...,  3.9451e-01,\n",
            "         -4.5201e-01, -2.3660e+00],\n",
            "        [-1.6630e+00, -1.3113e-03, -2.3230e+00,  ..., -3.8011e-01,\n",
            "         -2.3722e+00, -3.3705e-01]], grad_fn=<AddmmBackward0>)\n",
            "output:  torch.Size([128, 63])\n",
            "z_mul:  torch.Size([128, 63])\n",
            "\n",
            "DDECC Loss\n",
            "x_0:  torch.Size([128, 63])\n",
            "t:  torch.Size([65])\n",
            "t:  torch.Size([128])\n",
            "e:  torch.Size([128, 63])\n",
            "noise_factor:  torch.Size([128, 1])\n",
            "h:  torch.Size([63])\n",
            "yt:  torch.Size([128, 63])\n",
            "sum_syndrome:  torch.Size([128])\n",
            "\n",
            "DDECCT model\n",
            "magnitude:  torch.Size([128, 63])\n",
            "syndrome:  torch.Size([128, 18]) tensor([[ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        ...,\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1., -1.,  ..., -1., -1., -1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.]])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "time_emb:  torch.Size([128, 1, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "out_fc:  torch.Size([128, 63]) tensor([[-1.8772, -0.0389, -2.5001,  ..., -0.6013, -2.5972, -0.3332],\n",
            "        [-1.8456, -0.0535, -2.4952,  ..., -0.5352, -2.6484, -0.3778],\n",
            "        [-1.8469, -0.0561, -2.5406,  ..., -0.5401, -2.6452, -0.3593],\n",
            "        ...,\n",
            "        [-1.8767, -0.0839, -2.5561,  ..., -0.5631, -2.6425, -0.3726],\n",
            "        [ 0.1259, -1.1954,  0.0633,  ...,  0.8974, -0.2054, -3.4918],\n",
            "        [-1.9175, -0.0255, -2.4717,  ..., -0.5023, -2.7004, -0.3329]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "output:  torch.Size([128, 63])\n",
            "z_mul:  torch.Size([128, 63])\n",
            "\n",
            "DDECC Loss\n",
            "x_0:  torch.Size([128, 63])\n",
            "t:  torch.Size([65])\n",
            "t:  torch.Size([128])\n",
            "e:  torch.Size([128, 63])\n",
            "noise_factor:  torch.Size([128, 1])\n",
            "h:  torch.Size([63])\n",
            "yt:  torch.Size([128, 63])\n",
            "sum_syndrome:  torch.Size([128])\n",
            "\n",
            "DDECCT model\n",
            "magnitude:  torch.Size([128, 63])\n",
            "syndrome:  torch.Size([128, 18]) tensor([[ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        ...,\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1., -1.,  ..., -1., -1., -1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.]])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "time_emb:  torch.Size([128, 1, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "out_fc:  torch.Size([128, 63]) tensor([[-2.1165, -0.2145, -2.7456,  ..., -0.7701, -2.8306, -0.4357],\n",
            "        [-2.0779, -0.1822, -2.7955,  ..., -0.6910, -2.8371, -0.3483],\n",
            "        [-2.0503, -0.2421, -2.8108,  ..., -0.7165, -2.8513, -0.4811],\n",
            "        ...,\n",
            "        [-2.0778, -0.2240, -2.8029,  ..., -0.7097, -2.8859, -0.4378],\n",
            "        [-1.1082, -1.0341, -0.9692,  ...,  1.0907, -0.8527, -2.0908],\n",
            "        [-1.6003, -0.1380, -2.8535,  ..., -0.6190, -2.8234, -0.3405]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "output:  torch.Size([128, 63])\n",
            "z_mul:  torch.Size([128, 63])\n",
            "\n",
            "DDECC Loss\n",
            "x_0:  torch.Size([128, 63])\n",
            "t:  torch.Size([65])\n",
            "t:  torch.Size([128])\n",
            "e:  torch.Size([128, 63])\n",
            "noise_factor:  torch.Size([128, 1])\n",
            "h:  torch.Size([63])\n",
            "yt:  torch.Size([128, 63])\n",
            "sum_syndrome:  torch.Size([128])\n",
            "\n",
            "DDECCT model\n",
            "magnitude:  torch.Size([128, 63])\n",
            "syndrome:  torch.Size([128, 18]) tensor([[ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        ...,\n",
            "        [ 1.,  1., -1.,  ...,  1.,  1., -1.],\n",
            "        [-1.,  1.,  1.,  ..., -1., -1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.]])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "time_emb:  torch.Size([128, 1, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "out_fc:  torch.Size([128, 63]) tensor([[-2.2289, -0.3301, -2.9896,  ..., -0.8718, -3.1170, -0.5263],\n",
            "        [-2.2220, -0.3330, -3.1106,  ..., -0.9587, -3.1062, -0.5535],\n",
            "        [-2.2826, -0.3491, -3.0049,  ..., -0.8790, -3.0568, -0.5989],\n",
            "        ...,\n",
            "        [-1.5054, -2.0329, -0.1883,  ...,  0.9441, -0.4429, -1.7942],\n",
            "        [ 2.8797, -0.4680, -2.2024,  ...,  1.0425, -0.0113, -1.0384],\n",
            "        [-2.1465, -0.4531, -3.0216,  ..., -0.8967, -3.0098, -0.6180]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "output:  torch.Size([128, 63])\n",
            "z_mul:  torch.Size([128, 63])\n",
            "\n",
            "DDECC Loss\n",
            "x_0:  torch.Size([128, 63])\n",
            "t:  torch.Size([65])\n",
            "t:  torch.Size([128])\n",
            "e:  torch.Size([128, 63])\n",
            "noise_factor:  torch.Size([128, 1])\n",
            "h:  torch.Size([63])\n",
            "yt:  torch.Size([128, 63])\n",
            "sum_syndrome:  torch.Size([128])\n",
            "\n",
            "DDECCT model\n",
            "magnitude:  torch.Size([128, 63])\n",
            "syndrome:  torch.Size([128, 18]) tensor([[ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1., -1.,  1.,  ..., -1., -1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        ...,\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.]])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "time_emb:  torch.Size([128, 1, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "out_fc:  torch.Size([128, 63]) tensor([[-2.3215, -0.5343, -3.2891,  ..., -0.9436, -3.2372, -0.7627],\n",
            "        [-0.0354, -1.1746, -0.1177,  ...,  0.8315, -0.4504, -3.1029],\n",
            "        [-2.3612, -0.6142, -3.3097,  ..., -0.8619, -3.3017, -0.8227],\n",
            "        ...,\n",
            "        [-2.3987, -0.6256, -3.2982,  ..., -0.9540, -3.2577, -0.7612],\n",
            "        [-2.3513, -0.6212, -3.3445,  ..., -0.8974, -3.2722, -0.8063],\n",
            "        [-2.2498, -0.4407, -3.2342,  ..., -1.1108, -3.2091, -0.4643]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "output:  torch.Size([128, 63])\n",
            "z_mul:  torch.Size([128, 63])\n",
            "\n",
            "DDECC Loss\n",
            "x_0:  torch.Size([128, 63])\n",
            "t:  torch.Size([65])\n",
            "t:  torch.Size([128])\n",
            "e:  torch.Size([128, 63])\n",
            "noise_factor:  torch.Size([128, 1])\n",
            "h:  torch.Size([63])\n",
            "yt:  torch.Size([128, 63])\n",
            "sum_syndrome:  torch.Size([128])\n",
            "\n",
            "DDECCT model\n",
            "magnitude:  torch.Size([128, 63])\n",
            "syndrome:  torch.Size([128, 18]) tensor([[ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [-1.,  1., -1.,  ..., -1.,  1.,  1.],\n",
            "        ...,\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.]])\n",
            "emb:  torch.Size([128, 81, 32])\n",
            "time_emb:  torch.Size([128, 1, 32])\n",
            "emb:  torch.Size([128, 81, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-cac06efde73b>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     loss= train(model, device, train_dataloader, optimizer,\n\u001b[0m\u001b[1;32m     41\u001b[0m                             epoch, LR=scheduler.get_last_lr()[0])\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-9d79d757fc77>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch, LR)\u001b[0m\n\u001b[1;32m     60\u001b[0m     for batch_idx, (m, x, z, y, llr, magnitude, syndrome) in enumerate(\n\u001b[1;32m     61\u001b[0m             train_loader):\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_to_sign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DDECC/DDECC.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, x_0)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sum_syndrome: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_syndrome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_syndrome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DDECC/DDECC.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, y, time_step)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_emb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"emb: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, \" args.N_dec: \", self.args.N_dec)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_emb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"emb: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, \" args.N_dec: \", self.args.N_dec)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DDECC/DDECC.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask, time_emb)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;31m# x = time_emb*x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DDECC/DDECC.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DDECC/DDECC.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, sublayer)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msublayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msublayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DDECC/DDECC.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DDECC/DDECC.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, mask)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinears\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "args = pass_args_ddecc() # code_type, k, n\n",
        "\n",
        "code = args.code\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# MODEL #\n",
        "model = DDECCT(args, device=device,dropout=0).to(device)\n",
        "model.ema.register(model)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=args.epochs, eta_min=5e-6)\n",
        "\n",
        "print(model)\n",
        "print(f'# of Parameters: {np.sum([np.prod(p.shape) for p in model.parameters()])}')\n",
        "\n",
        "#################################\n",
        "EbNo_range_test = range(4, 7)\n",
        "EbNo_range_train = range(2, 8)\n",
        "std_train = [EbN0_to_std(ii, code.k / code.n) for ii in EbNo_range_train]\n",
        "std_test = [EbN0_to_std(ii, code.k / code.n) for ii in EbNo_range_test]\n",
        "train_dataloader = DataLoader(FEC_Dataset(code, std_train, len=args.batch_size * 1000, zero_cw=True), batch_size=int(args.batch_size),\n",
        "                              shuffle=True, num_workers=args.workers)\n",
        "test_dataloader_list = [DataLoader(FEC_Dataset(code, [std_test[ii]], len=int(args.test_batch_size), zero_cw=False),\n",
        "                                    batch_size=int(args.test_batch_size), shuffle=False, num_workers=args.workers) for ii in range(len(std_test))]\n",
        "#################################\n",
        "\n",
        "print(f\"Training model with code type: {args.code_type}\")\n",
        "print(args.code_type)\n",
        "\n",
        "\n",
        "best_loss = float('inf')\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    loss= train(model, device, train_dataloader, optimizer,\n",
        "                            epoch, LR=scheduler.get_last_lr()[0])\n",
        "\n",
        "    scheduler.step()\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "        torch.save(model, os.path.join(args.path, 'best_model'))\n",
        "        print(f'Model Saved')\n",
        "    if epoch % 5 == 0 or epoch in [1,25]:\n",
        "\n",
        "\n",
        "        test(model, device, test_dataloader_list, EbNo_range_test,min_FER=50,max_cum_count=1e6,min_cum_count=1e4)\n",
        "#################################\n",
        "\n",
        "print('Regular Reverse Diffusion')\n",
        "test(model, device, test_dataloader_list, EbNo_range_test,min_FER=100)\n",
        "print('Line Search Reverse Diffusion')\n",
        "model.line_search = True\n",
        "test(model, device, test_dataloader_list, EbNo_range_test,min_FER=100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, Dense\n",
        "from gnn_decoder.gnn import UpdateEmbeddings\n",
        "\n",
        "\n",
        "def train_gnn(model, device, train_loader, epoch, LR):\n",
        "    # model.train()\n",
        "    cum_loss = cum_samples = 0\n",
        "    t = time.time()\n",
        "    loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
        "\n",
        "    for batch_idx, (m, x, z, y, llr, magnitude, syndrome) in enumerate(train_loader):\n",
        "        # convert to tf for GNN_BP\n",
        "        llr = tf.convert_to_tensor(llr.numpy(), dtype=tf.float32)\n",
        "\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "          # model prediction\n",
        "          x_hat = model(llr)\n",
        "\n",
        "          loss = loss_fn(x, x_hat)\n",
        "\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        cum_loss += loss * x.shape[0]\n",
        "        cum_samples += x.shape[0]\n",
        "        if (batch_idx+1) % 10 == 0 or batch_idx == len(train_loader) - 1:\n",
        "            print(f'Training epoch {epoch}, Batch {batch_idx + 1}/{len(train_loader)}: LR={LR:.2e}, Loss={cum_loss / cum_samples:.5e}')\n",
        "\n",
        "    print(f'Epoch {epoch} Train Time {time.time() - t}s\\n')\n",
        "    return cum_loss / cum_samples\n",
        "\n",
        "\n",
        "\n",
        "def test_gnn(model, device, test_loader_list, EbNo_range_test, min_FER=100, max_cum_count=1e7, min_cum_count=1e5):\n",
        "    # model.eval()\n",
        "    test_loss_ber_list, test_loss_fer_list, cum_samples_all = [], [], []\n",
        "    t = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for ii, test_loader in enumerate(test_loader_list):\n",
        "            test_ber = test_fer = cum_count = 0.\n",
        "\n",
        "            # _, x_pred_list, _, _ = model.p_sample_loop(next(iter(test_loader))[3])\n",
        "            # test_ber_ddpm , test_fer_ddpm = [0]*len(x_pred_list), [0]*len(x_pred_list)\n",
        "            idx_conv_all = []\n",
        "\n",
        "            while True:\n",
        "                (m, x, z, y, magnitude, syndrome) = next(iter(test_loader))\n",
        "\n",
        "                # x_pred, x_pred_list, idx_conv,synd_all = model.p_sample_loop(y)\n",
        "                # x_pred = sign_to_bin(torch.sign(x_pred))\n",
        "\n",
        "                # idx_conv_all.append(idx_conv)\n",
        "\n",
        "                for kk, x_pred_tmp in enumerate(x_pred_list):\n",
        "                    x_pred_tmp = sign_to_bin(torch.sign(x_pred_tmp))\n",
        "\n",
        "                    test_ber_ddpm[kk] += BER(x_pred_tmp, x) * x.shape[0]\n",
        "                    test_fer_ddpm[kk] += FER(x_pred_tmp, x) * x.shape[0]\n",
        "\n",
        "                test_ber += BER(x_pred, x) * x.shape[0]\n",
        "                test_fer += FER(x_pred, x) * x.shape[0]\n",
        "                cum_count += x.shape[0]\n",
        "\n",
        "                if (min_FER > 0 and test_fer > min_FER and cum_count > min_cum_count) or cum_count >= max_cum_count:\n",
        "                    if cum_count >= 1e9:\n",
        "                        print(f'Cum count reached EbN0:{EbNo_range_test[ii]}')\n",
        "                    else:\n",
        "                        print(f'FER count treshold reached EbN0:{EbNo_range_test[ii]}')\n",
        "                    break\n",
        "\n",
        "            idx_conv_all = torch.stack(idx_conv_all).float()\n",
        "            cum_samples_all.append(cum_count)\n",
        "            test_loss_ber_list.append(test_ber / cum_count)\n",
        "            test_loss_fer_list.append(test_fer / cum_count)\n",
        "\n",
        "            for kk in range(len(test_ber_ddpm)):\n",
        "                test_ber_ddpm[kk] /= cum_count\n",
        "                test_fer_ddpm[kk] /= cum_count\n",
        "            print(f'Test EbN0={EbNo_range_test[ii]}, BER={test_loss_ber_list}')\n",
        "            print(f'Test EbN0={EbNo_range_test[ii]}, BER_DDPM={test_ber_ddpm}')\n",
        "            print(f'Test EbN0={EbNo_range_test[ii]}, -ln(BER)_DDPM={[-np.log(elem) for elem in test_ber_ddpm]}')\n",
        "            print(f'Test EbN0={EbNo_range_test[ii]}, FER_DDPM={test_fer_ddpm}')\n",
        "            print(f'#It. to zero syndrome: Mean={idx_conv_all.mean()}, Std={idx_conv_all.std()}, Min={idx_conv_all.min()}, Max={idx_conv_all.max()}')\n",
        "\n",
        "        print('Test FER ' + ' '.join(\n",
        "            ['{}: {:.2e}'.format(ebno, elem) for (elem, ebno)\n",
        "             in\n",
        "             (zip(test_loss_fer_list, EbNo_range_test))]))\n",
        "        print('Test BER ' + ' '.join(\n",
        "            ['{}: {:.2e}'.format(ebno, elem) for (elem, ebno)\n",
        "             in\n",
        "             (zip(test_loss_ber_list, EbNo_range_test))]))\n",
        "        print('Test -ln(BER) ' + ' '.join(\n",
        "            ['{}: {:.2e}'.format(ebno, -np.log(elem)) for (elem, ebno)\n",
        "             in\n",
        "             (zip(test_loss_ber_list, EbNo_range_test))]))\n",
        "    print(f'# of testing samples: {cum_samples_all}\\n Test Time {time.time() - t} s\\n')\n",
        "    return test_loss_ber_list, test_loss_fer_list\n",
        "\n",
        "\n",
        "\n",
        "gnn = GNN_BP(code)\n",
        "\n",
        "train_gnn(gnn, device, train_dataloader, epoch, LR=scheduler.get_last_lr()[0])\n",
        "# test_gnn(gnn, device, test_dataloader_list, EbNo_range_test,min_FER=50,max_cum_count=1e6,min_cum_count=1e4)"
      ],
      "metadata": {
        "id": "Me_wsbYE7iIj",
        "outputId": "415fc470-8ad1-4cb4-e01c-d096dd78652f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1, Batch 10/1000: LR=5.00e-04, Loss=3.24446e-01\n",
            "Training epoch 1, Batch 20/1000: LR=5.00e-04, Loss=1.93297e-01\n",
            "Training epoch 1, Batch 30/1000: LR=5.00e-04, Loss=1.36352e-01\n",
            "Training epoch 1, Batch 40/1000: LR=5.00e-04, Loss=1.05236e-01\n",
            "Training epoch 1, Batch 50/1000: LR=5.00e-04, Loss=8.57611e-02\n",
            "Training epoch 1, Batch 60/1000: LR=5.00e-04, Loss=7.24461e-02\n",
            "Training epoch 1, Batch 70/1000: LR=5.00e-04, Loss=6.27684e-02\n",
            "Training epoch 1, Batch 80/1000: LR=5.00e-04, Loss=5.54122e-02\n",
            "Training epoch 1, Batch 90/1000: LR=5.00e-04, Loss=4.96271e-02\n",
            "Training epoch 1, Batch 100/1000: LR=5.00e-04, Loss=4.49552e-02\n",
            "Training epoch 1, Batch 110/1000: LR=5.00e-04, Loss=4.11005e-02\n",
            "Training epoch 1, Batch 120/1000: LR=5.00e-04, Loss=3.78642e-02\n",
            "Training epoch 1, Batch 130/1000: LR=5.00e-04, Loss=3.51074e-02\n",
            "Training epoch 1, Batch 140/1000: LR=5.00e-04, Loss=3.27301e-02\n",
            "Training epoch 1, Batch 150/1000: LR=5.00e-04, Loss=3.06583e-02\n",
            "Training epoch 1, Batch 160/1000: LR=5.00e-04, Loss=2.88362e-02\n",
            "Training epoch 1, Batch 170/1000: LR=5.00e-04, Loss=2.72210e-02\n",
            "Training epoch 1, Batch 180/1000: LR=5.00e-04, Loss=2.57791e-02\n",
            "Training epoch 1, Batch 190/1000: LR=5.00e-04, Loss=2.44838e-02\n",
            "Training epoch 1, Batch 200/1000: LR=5.00e-04, Loss=2.33138e-02\n",
            "Training epoch 1, Batch 210/1000: LR=5.00e-04, Loss=2.22515e-02\n",
            "Training epoch 1, Batch 220/1000: LR=5.00e-04, Loss=2.12827e-02\n",
            "Training epoch 1, Batch 230/1000: LR=5.00e-04, Loss=2.03955e-02\n",
            "Training epoch 1, Batch 240/1000: LR=5.00e-04, Loss=1.95799e-02\n",
            "Training epoch 1, Batch 250/1000: LR=5.00e-04, Loss=1.88276e-02\n",
            "Training epoch 1, Batch 260/1000: LR=5.00e-04, Loss=1.81314e-02\n",
            "Training epoch 1, Batch 270/1000: LR=5.00e-04, Loss=1.74853e-02\n",
            "Training epoch 1, Batch 280/1000: LR=5.00e-04, Loss=1.68840e-02\n",
            "Training epoch 1, Batch 290/1000: LR=5.00e-04, Loss=1.63229e-02\n",
            "Training epoch 1, Batch 300/1000: LR=5.00e-04, Loss=1.57982e-02\n",
            "Training epoch 1, Batch 310/1000: LR=5.00e-04, Loss=1.53065e-02\n",
            "Training epoch 1, Batch 320/1000: LR=5.00e-04, Loss=1.48446e-02\n",
            "Training epoch 1, Batch 330/1000: LR=5.00e-04, Loss=1.44100e-02\n",
            "Training epoch 1, Batch 340/1000: LR=5.00e-04, Loss=1.40002e-02\n",
            "Training epoch 1, Batch 350/1000: LR=5.00e-04, Loss=1.36133e-02\n",
            "Training epoch 1, Batch 360/1000: LR=5.00e-04, Loss=1.32473e-02\n",
            "Training epoch 1, Batch 370/1000: LR=5.00e-04, Loss=1.29006e-02\n",
            "Training epoch 1, Batch 380/1000: LR=5.00e-04, Loss=1.25718e-02\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOJxrBiii/B+BddJxGsXpAX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}