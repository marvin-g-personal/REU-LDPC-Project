{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObpNegr0X1WEwR+vwpjR8b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pollyjuice74/REU-LDPC-Project/blob/main/LinearTranDiff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXwLdxMGTjF8",
        "outputId": "4d7e0cef-fa37-4eb4-ea54-838ac95f68b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'REU-LDPC-Project'...\n",
            "remote: Enumerating objects: 701, done.\u001b[K\n",
            "remote: Counting objects: 100% (292/292), done.\u001b[K\n",
            "remote: Compressing objects: 100% (143/143), done.\u001b[K\n",
            "remote: Total 701 (delta 185), reused 233 (delta 147), pack-reused 409\u001b[K\n",
            "Receiving objects: 100% (701/701), 580.88 KiB | 4.54 MiB/s, done.\n",
            "Resolving deltas: 100% (387/387), done.\n",
            "Cloning into 'DDECC'...\n",
            "remote: Enumerating objects: 613, done.\u001b[K\n",
            "remote: Counting objects: 100% (345/345), done.\u001b[K\n",
            "remote: Compressing objects: 100% (233/233), done.\u001b[K\n",
            "remote: Total 613 (delta 191), reused 183 (delta 98), pack-reused 268\u001b[K\n",
            "Receiving objects: 100% (613/613), 1.08 GiB | 30.89 MiB/s, done.\n",
            "Resolving deltas: 100% (276/276), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pollyjuice74/REU-LDPC-Project\n",
        "!git clone https://github.com/pollyjuice74/DDECC\n",
        "!wget https://raw.githubusercontent.com/NVlabs/sionna/main/sionna/utils/metrics.py -O metrics.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "if os.path.exists('REU-LDPC-Project'):\n",
        "  os.rename('REU-LDPC-Project', 'REU_LDPC_Project')\n",
        "os.chdir('REU_LDPC_Project/adv_nn')\n",
        "\n",
        "from attention import *\n",
        "from channel import *\n",
        "from decoder import *\n",
        "from model import *\n",
        "from dataset import *\n",
        "from args import *\n",
        "\n",
        "from metrics import BitErrorRate as ber\n",
        "from metrics import compute_bler as bler\n",
        "from DDECC.src.codes import EbN0_to_std\n",
        "\n",
        "os.chdir('../../DDECC')"
      ],
      "metadata": {
        "id": "e-lnoCOdT9LS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train(model, train_loader, optimizer, epoch, LR):\n",
        "    pass\n",
        "\n",
        "\n",
        "from metrics import compute_bler as bler\n",
        "def test(model, test_loader_list, EbNo_range_test, min_FER=100, max_cum_count=1e7, min_cum_count=1e5):\n",
        "    printed = False\n",
        "    ber_list, bler_list = [], []\n",
        "\n",
        "    for ix, test_loader in enumerate(test_loader_list):\n",
        "        for batch_ix, (m, c, z, r, _, _, magnitude, syndrome) in enumerate(test_loader):\n",
        "            c_hat = model(r)\n",
        "            ber_list.append(ber(c, c_hat))\n",
        "            bler_list.append(bler(c, c_hat))\n",
        "            print(f'Test EbN0={EbNo_range_test[ix]}, BER={ber_list[-1]}')\n",
        "            print(f'Test EbN0={EbNo_range_test[ix]}, BLER={bler_list[-1]}')\n",
        "\n",
        "            if not printed:\n",
        "              print(\"c: \", c)\n",
        "              print(\"c_hat: \", c_hat)\n",
        "              printed = True\n",
        "            break\n",
        "\n",
        "    return { \"ber\": ber_list, \"bler\": bler_list }\n",
        "\n",
        "\n",
        "def test_models():\n",
        "    data = { \"LTDM\": dict() }\n",
        "\n",
        "    for ix, tst_dataset in enumerate(test_ebnos_datasets):\n",
        "        print(f\"\\nTesting on {list(dataset_types.keys())[ix].upper()}\")\n",
        "        print(\"Testing  Linear Transformer Diffusion Model...\")\n",
        "        data[\"LTDM\"][ix] = test(dec, tst_dataset, EbNo_range_test, min_FER=50,max_cum_count=1e6,min_cum_count=1e4)\n",
        "        return data\n",
        "\n",
        "\n",
        "args = Args(model_type='dis') # args for decoder/discriminator\n",
        "dataset = FEC_Dataset(args.code, args.sigma, zero_cw=True)\n",
        "dec = Discriminator(args)\n",
        "\n",
        "EbNo_range_train = range(2, 8)\n",
        "EbNo_range_test = range(4, 8)\n",
        "# Standard deviation for train/test\n",
        "std_train = [EbN0_to_std(ii, args.k / args.n) for ii in EbNo_range_train]\n",
        "std_test = [EbN0_to_std(ii, args.k / args.n) for ii in EbNo_range_test]\n",
        "\n",
        "scheduler = tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate=args.lr, decay_steps=args.epochs) # 1000 is size of trainloader\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=scheduler)\n",
        "\n",
        "train_dataloader = FEC_Dataset(args.code, sigma=std_test, length=args.traindata_len) \\\n",
        "                              .batch(args.batch_size).shuffle(buffer_size=args.batch_size)\n",
        "#                         z_cw   m 1s   1-cw     Should use zero codeword by default\n",
        "dataset_types = {\n",
        "              \"awgn\":    (False, False, False), # Binary bits sent and recieved with some awgn\n",
        "              \"flip_cw\": (True, False, True),   # Zero codeword flipped to a all ones vector [1,1,...,1]\n",
        "              \"zero_cw\": (True, False, False),  # Standard zero codeword used for training\n",
        "              \"ones_m\":  (False, True, False),  # Makes the message all ones vector and passes it to generator matrix producing codeword and pcm\n",
        "              }\n",
        "test_ebnos_datasets = [ [FEC_Dataset(args.code, sigma=std_test, zero_cw=zero_cw, ones_m=ones_m, flip_cw=flip_cw)\n",
        "                                 for ii in range(len(std_test))]\n",
        "                                 for (zero_cw, ones_m, flip_cw) in dataset_types.values() ]\n",
        "\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    # print(\"Training Linear Transformer Diffusion Model...\")\n",
        "    # train(dec, train_dataloader, optimizer, epoch, LR=scheduler(tf.Variable(0, dtype=tf.float32)).numpy())\n",
        "\n",
        "    # print comparison\n",
        "    if epoch % 1 == 0:\n",
        "        data = test_models()\n",
        "    break # from for loop\n",
        "\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tN1zJuxWd6Vl",
        "outputId": "7984f393-8006-4692-c16f-b446065ffb72"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing on AWGN\n",
            "Testing  Linear Transformer Diffusion Model...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnknownError",
          "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} NameError: name 'args' is not defined\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/content/REU_LDPC_Project/adv_nn/dataset.py\", line 39, in _generator\n    z = tf.random.normal((args.code.n,), std_noise)\n\nNameError: name 'args' is not defined\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-07a2914f24de>\u001b[0m in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# print comparison\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32mbreak\u001b[0m \u001b[0;31m# from for loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-07a2914f24de>\u001b[0m in \u001b[0;36mtest_models\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nTesting on {list(dataset_types.keys())[ix].upper()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing  Linear Transformer Diffusion Model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"LTDM\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtst_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEbNo_range_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_FER\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_cum_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_cum_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-07a2914f24de>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, test_loader_list, EbNo_range_test, min_FER, max_cum_count, min_cum_count)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagnitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyndrome\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mc_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mber_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    808\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    774\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3027\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3029\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5882\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5883\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} NameError: name 'args' is not defined\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/content/REU_LDPC_Project/adv_nn/dataset.py\", line 39, in _generator\n    z = tf.random.normal((args.code.n,), std_noise)\n\nNameError: name 'args' is not defined\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-0S8yHWtEChg"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}
